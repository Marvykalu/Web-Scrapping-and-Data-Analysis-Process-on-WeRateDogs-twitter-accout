{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size = \"12\" color = lightblue> <div align=\"center\"> Wrangle Report </div> </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangling and analyzing data is one of the projects I get to do as a student in the Udacity Data Analyst Nanodegree program.\n",
    "\n",
    "Specifically, my tasks in the project are as follows:\n",
    "\n",
    "* Data wrangling, which consists of:\n",
    " * Gathering data \n",
    " * Assessing data\n",
    " * Cleaning data\n",
    "* Storing, analyzing, and visualizing your wrangled data\n",
    "* Reporting on \n",
    " * your data wrangling efforts \n",
    " * your data analyses and visualizations\n",
    "\n",
    "Thus this report reports my data wrangling effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What data do we have?\n",
    "\n",
    "The data we wrangle and analyze in this project comes from the twitter archive of twitter user [@dog_rates](https://twitter.com/dog_rates). Since it is a real-world data, it sure is dirty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What software?\n",
    "\n",
    "To wrangle WeRateDogs Twitter data, I’m going to use Python to wrangle the data. We’ll use\n",
    "* pandas,\n",
    "* Numpy,\n",
    "* request\n",
    "* tweepy and \n",
    "* json \n",
    "libraries to help build up our dataframe.\n",
    "\n",
    "I’m using a Jupyter Notebook to code in and and you can get the finished product from my Github repo.\n",
    "\n",
    "**Let's take a look at how these packages are imported**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all packages needed\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Data wrangling steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Gathering data:\n",
    "\n",
    "There are three pieces of data to be gathered.\n",
    "\n",
    "* **The WeRateDogs Twitter archive**: this was manually downloaded by clicking the twitter_archive_enhanced.csv in Udacity resource page\n",
    "* **The tweet image predictions** (image_predictions.tsv) that tells us what breed of dog is present in each tweet according to a neural network. The is hosted on Udacity's servers and was downloaded programmatically using the Requests library and the following URL: [image_predictions.tsv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "* **Additional Data via the Twitter API**: I will query Twitter's API to gather valuable data such as retweet count, favorites count. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Assessing Data\n",
    "\n",
    "Here we identify issues with our data. This identification can be done \n",
    "* **Visually**; by opening the data in a spreadsheet. I first opened the data in an excel spreadsheet.\n",
    "* **Programmatically**; by writing codes that call some functions in Pandas such as\n",
    " * df.head()/tail() : would print first/last 5 lines in the data set\n",
    " * df.describe: would print statistical properties ofthe qualitative variables.\n",
    " * df.info(): would print information about data types, number of rows and colums, Null and Non-Null variables, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of issues in dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Duplicates in the image_prediction table\n",
    "* Outliers in numerator rating\n",
    "* Missing values in dog stage column.\n",
    "* Inaccurate entery of dog names\n",
    "* Mising images in some tweets\n",
    "* We are interested in only original tweets, so there are 181 retweets to be deleted\n",
    "* Incorrect datatypes of some variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues:\n",
    "\n",
    "* Merging the three pieces of data into a single dataframe\n",
    "* The different dog stages were each represented in a column. We need to melt all stages into a single column callled **Dog_stage**\n",
    "* Deleteing columns that are not useful for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cleaning data\n",
    "\n",
    "We have assessed our data and listed certain issues in the data that would require cleaning. To actually perform cleaning, the following steps are considered:\n",
    "\n",
    "* **Define**: state the issue to be cleaned and how we will go about cleaning it.\n",
    "* **Code**: write down the code that does the cleaning operation\n",
    "* **Test**: Test your code to see that the defined cleaning operation was performed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "At the of the data wrangling process, the following reports were put together to convey our observations and procedures;\n",
    "\n",
    "* **wrangle_act.ipynb**: complete documentation of codes, data wrangling processes, analysis and visualizations.\n",
    "* **act_report.html**: documentation of insights and visuals to final (cleaned) data\n",
    "* **wrangle_report.html**: documentation of data wrangling steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
